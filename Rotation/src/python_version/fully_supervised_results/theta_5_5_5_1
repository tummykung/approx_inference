num_samples:	1875
100: train dataset average log-likelihood:	-2.07161034626
200: train dataset average log-likelihood:	-1.44703136913
300: train dataset average log-likelihood:	-1.25398028527
400: train dataset average log-likelihood:	-1.17260562837
500: train dataset average log-likelihood:	-1.13642858404
600: train dataset average log-likelihood:	-1.11429900747
700: train dataset average log-likelihood:	-1.09963292857
800: train dataset average log-likelihood:	-1.08947065283
900: train dataset average log-likelihood:	-1.084804572
1000: train dataset average log-likelihood:	-1.08046278323
1100: train dataset average log-likelihood:	-1.07651531214
1200: train dataset average log-likelihood:	-1.07281519753
1300: train dataset average log-likelihood:	-1.06957494807
1400: train dataset average log-likelihood:	-1.06743931057
1500: train dataset average log-likelihood:	-1.06610489703
1600: train dataset average log-likelihood:	-1.06514011328
1625: train dataset average log-likelihood:	-1.06489814509

xi:	no relaxation
rangeY:	[9, 9, 9]
vocab size(X):	5
fully_supervised?:	True

===== expert statistics =====
true_theta:	[ 5.  5.  5.  1.]
best_expert_train_dataset_average_log_likelihood:	-1.05949859805
test dataset average log-likelihood:	-0.817037059586
best_expert_test_dataset_average_log_likelihood:	-0.817037059586
best_expert_accuracy:	0.88 (220/250)

===== learner statistics =====
learned_theta:	[ 4.73540802  4.69090281  4.74670829  0.01533827]
learner_train_dataset_average_log_likelihood:	-1.06489814509
test dataset average log-likelihood:	-0.834952210205
learner_test_dataset_average_log_likelihood:	-0.834952210205
learner_accuracy:	0.88 (220/250)

num_samples:	1875
100: train dataset average log-likelihood:	-6.90122837904
200: train dataset average log-likelihood:	-6.90318190669
300: train dataset average log-likelihood:	-6.89946316836
400: train dataset average log-likelihood:	-6.8945298183
500: train dataset average log-likelihood:	-6.89265746905
600: train dataset average log-likelihood:	-6.89176046421
700: train dataset average log-likelihood:	-6.89158887687
800: train dataset average log-likelihood:	-6.89155387277
900: train dataset average log-likelihood:	-6.89131180924
1000: train dataset average log-likelihood:	-6.89136124383
1100: train dataset average log-likelihood:	-6.89088893203
1200: train dataset average log-likelihood:	-6.89069794222
1300: train dataset average log-likelihood:	-6.89017502872
1400: train dataset average log-likelihood:	-6.88957085595
1500: train dataset average log-likelihood:	-6.88903450807
1600: train dataset average log-likelihood:	-6.88885901125
1625: train dataset average log-likelihood:	-6.88885811558

xi:	no relaxation
rangeY:	[9, 9, 9]
vocab size(X):	5
fully_supervised?:	True

===== expert statistics =====
true_theta:	[ 0.5  0.2  0.1  1. ]
best_expert_train_dataset_average_log_likelihood:	-6.88818675874
test dataset average log-likelihood:	-6.89114060489
best_expert_test_dataset_average_log_likelihood:	-6.89114060489
best_expert_accuracy:	0.0 (0/250)

===== learner statistics =====
learned_theta:	[ 0.47884294  0.17355392  0.07077269  0.15879167]
learner_train_dataset_average_log_likelihood:	-6.88885811558
test dataset average log-likelihood:	-6.89084947104
learner_test_dataset_average_log_likelihood:	-6.89084947104
learner_accuracy:	0.004 (1/250)

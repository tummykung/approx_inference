num_samples:	1875
100: train dataset average log-likelihood:	-6.90484047112
200: train dataset average log-likelihood:	-6.90535810721
300: train dataset average log-likelihood:	-6.90149114207
400: train dataset average log-likelihood:	-6.89772265531
500: train dataset average log-likelihood:	-6.89577410228
600: train dataset average log-likelihood:	-6.89473324872
700: train dataset average log-likelihood:	-6.89468479645
800: train dataset average log-likelihood:	-6.89477485535
900: train dataset average log-likelihood:	-6.89513527272
1000: train dataset average log-likelihood:	-6.89505323822
1100: train dataset average log-likelihood:	-6.89417198896
1200: train dataset average log-likelihood:	-6.89370254537
1300: train dataset average log-likelihood:	-6.89349174861
1400: train dataset average log-likelihood:	-6.893388321
1500: train dataset average log-likelihood:	-6.89332108687
1600: train dataset average log-likelihood:	-6.89327046008
1625: train dataset average log-likelihood:	-6.89325847647

xi:	no relaxation
rangeY:	[9, 9, 9]
vocab size(X):	5
fully_supervised?:	True

===== expert statistics =====
true_theta:	[ 0.5  0.2  0.1  0. ]
best_expert_train_dataset_average_log_likelihood:	-6.89343245139
test dataset average log-likelihood:	-6.87617091293
best_expert_test_dataset_average_log_likelihood:	-6.87617091293
best_expert_accuracy:	0.0 (0/250)

===== learner statistics =====
learned_theta:	[ 0.45032704  0.08572919  0.02757455 -0.01131316]
learner_train_dataset_average_log_likelihood:	-6.89325847647
test dataset average log-likelihood:	-6.88065531365
learner_test_dataset_average_log_likelihood:	-6.88065531365
learner_accuracy:	0.0 (0/250)

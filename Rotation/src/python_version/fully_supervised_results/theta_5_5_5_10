num_samples:	1875
100: train dataset average log-likelihood:	-3.10669168327
200: train dataset average log-likelihood:	-2.33825836399
300: train dataset average log-likelihood:	-1.97963944306
400: train dataset average log-likelihood:	-1.74456192602
500: train dataset average log-likelihood:	-1.57342428841
600: train dataset average log-likelihood:	-1.4532643511
700: train dataset average log-likelihood:	-1.3661006599
800: train dataset average log-likelihood:	-1.30315005866
900: train dataset average log-likelihood:	-1.25233493961
1000: train dataset average log-likelihood:	-1.21223115734
1100: train dataset average log-likelihood:	-1.18059183102
1200: train dataset average log-likelihood:	-1.1549230855
1300: train dataset average log-likelihood:	-1.13586027509
1400: train dataset average log-likelihood:	-1.12020606164
1500: train dataset average log-likelihood:	-1.10975426851
1600: train dataset average log-likelihood:	-1.09974807207
1625: train dataset average log-likelihood:	-1.09735917979

xi:	no relaxation
rangeY:	[9, 9, 9]
vocab size(X):	5
fully_supervised?:	True

===== expert statistics =====
true_theta:	[  5.   5.   5.  10.]
best_expert_train_dataset_average_log_likelihood:	-1.02525125613
test dataset average log-likelihood:	-1.16063587151
best_expert_test_dataset_average_log_likelihood:	-1.16063587151
best_expert_accuracy:	0.648 (162/250)

===== learner statistics =====
learned_theta:	[ 4.33308729  4.31687618  4.47071475  8.18927956]
learner_train_dataset_average_log_likelihood:	-1.09735917979
test dataset average log-likelihood:	-1.19474106374
learner_test_dataset_average_log_likelihood:	-1.19474106374
learner_accuracy:	0.684 (171/250)

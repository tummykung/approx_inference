num_samples:	1875
100: train dataset average log-likelihood:	-6.89943538634
200: train dataset average log-likelihood:	-6.89595625342
300: train dataset average log-likelihood:	-6.89404766483
400: train dataset average log-likelihood:	-6.89444356027
500: train dataset average log-likelihood:	-6.89334668689
600: train dataset average log-likelihood:	-6.89249382424
700: train dataset average log-likelihood:	-6.89217673344
800: train dataset average log-likelihood:	-6.89195358853
900: train dataset average log-likelihood:	-6.89204000385
1000: train dataset average log-likelihood:	-6.89210452114
1100: train dataset average log-likelihood:	-6.89186019793
1200: train dataset average log-likelihood:	-6.89163938528
1300: train dataset average log-likelihood:	-6.89167433368
1400: train dataset average log-likelihood:	-6.89168771708
1500: train dataset average log-likelihood:	-6.89168260375
1600: train dataset average log-likelihood:	-6.89166555556
1625: train dataset average log-likelihood:	-6.89168215554

xi:	no relaxation
rangeY:	[9, 9, 9]
vocab size(X):	5
fully_supervised?:	True

===== expert statistics =====
true_theta:	[ 0.5  0.2  0.1  0. ]
best_expert_train_dataset_average_log_likelihood:	-6.89170937446
test dataset average log-likelihood:	-6.90617091293
best_expert_test_dataset_average_log_likelihood:	-6.90617091293
best_expert_accuracy:	0.004 (1/250)

===== learner statistics =====
learned_theta:	[ 0.46539882  0.16057694  0.0484051  -0.01101094]
learner_train_dataset_average_log_likelihood:	-6.89168215554
test dataset average log-likelihood:	-6.90456229917
learner_test_dataset_average_log_likelihood:	-6.90456229917
learner_accuracy:	0.004 (1/250)

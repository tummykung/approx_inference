num_samples:	1875
100: train dataset average log-likelihood:	-2.13196518398
200: train dataset average log-likelihood:	-1.44109574452
300: train dataset average log-likelihood:	-1.26176261876
400: train dataset average log-likelihood:	-1.18770946566
500: train dataset average log-likelihood:	-1.15125223369
600: train dataset average log-likelihood:	-1.13253466544
700: train dataset average log-likelihood:	-1.12017636004
800: train dataset average log-likelihood:	-1.10999490366
900: train dataset average log-likelihood:	-1.103525867
1000: train dataset average log-likelihood:	-1.09942697555
1100: train dataset average log-likelihood:	-1.09620310406
1200: train dataset average log-likelihood:	-1.0925872154
1300: train dataset average log-likelihood:	-1.08963458935
1400: train dataset average log-likelihood:	-1.08737035326
1500: train dataset average log-likelihood:	-1.0853078032
1600: train dataset average log-likelihood:	-1.08311285315
1625: train dataset average log-likelihood:	-1.0825286455

xi:	no relaxation
rangeY:	[9, 9, 9]
vocab size(X):	5
fully_supervised?:	True

===== expert statistics =====
true_theta:	[ 5.  5.  5.  5.]
best_expert_train_dataset_average_log_likelihood:	-1.034097901
test dataset average log-likelihood:	-1.04332867024
best_expert_test_dataset_average_log_likelihood:	-1.04332867024
best_expert_accuracy:	0.832 (208/250)

===== learner statistics =====
learned_theta:	[ 4.47100833  4.61786319  5.07863977  1.15233225]
learner_train_dataset_average_log_likelihood:	-1.0825286455
test dataset average log-likelihood:	-1.08856167399
learner_test_dataset_average_log_likelihood:	-1.08856167399
learner_accuracy:	0.832 (208/250)
